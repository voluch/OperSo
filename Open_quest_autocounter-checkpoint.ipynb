{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing all necessary packages\n",
    "\n",
    "from deep_translator import GoogleTranslator\n",
    "from autocorrect import Speller\n",
    "from langdetect import detect\n",
    "import xlwings as xw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "import chardet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-relation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### All \"magic\" is here\n",
    "\n",
    "\n",
    "filename = \"test3.xlsx\"\n",
    "wb = xw.Book(filename)\n",
    "ws = wb.sheets[0]\n",
    "a_range = ws.used_range.address\n",
    "\n",
    "\n",
    "x = ws.used_range.value\n",
    "df = pd.DataFrame (x,columns=['source'])\n",
    "df['cleaned'] = ''\n",
    "df['lang'] = ''\n",
    "df['corrected'] = ''\n",
    "df['translated'] = ''\n",
    "\n",
    "\n",
    "\n",
    "ukr_spell = Speller('uk')\n",
    "ru_spell  = Speller('ru')\n",
    "\n",
    "\n",
    "### Preprocessing data\n",
    "for ind in df.index:\n",
    "    ### Cleaning data\n",
    "    \n",
    "    ## '[.:;]' - replacing '.' to ','\n",
    "    ## '[.,]$' - removing ',' and '.' at the end of string\n",
    "    ## '(?a:^\\s+|\\s+$)' - removing some whitespaces at the string\n",
    "    ## '[\\]\\[(+*)\\n\\_?]' - removing useless symbosl from string (can be changed by adding more symbols)\n",
    "    df['cleaned'][ind] =  re.sub('[.:;]', ',', re.sub('[.,]$', '', re.sub('(?a:^\\s+|\\s+$)','', re.sub('[\\]\\[(+*)\\n\\_?]', '', df['source'][ind]))))\n",
    "    ## .str.lower() - lower all chars\n",
    "    ## .str.strip() - removing whitespaces, so that only one whitespace can be between two words\n",
    "    df['cleaned'][ind] = df['cleaned'][ind].lower()\n",
    "    df['cleaned'][ind] = df['cleaned'][ind].strip()\n",
    "    \n",
    "    \n",
    "    ### Detecting language\n",
    "    df['lang'][ind] = detect(df['cleaned'][ind])\n",
    "    if detect(df['cleaned'][ind]) == 'uk':\n",
    "        df['corrected'][ind] = ukr_spell(df['cleaned'][ind])\n",
    "        df['translated'][ind] = df['corrected'][ind]\n",
    "    else:\n",
    "        df['corrected'][ind] = ru_spell(df['cleaned'][ind])\n",
    "        df['translated'][ind] = GoogleTranslator(source='english', target='ukrainian').translate(GoogleTranslator(source='russian', target='english').translate(df['corrected'][ind]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clustering preprocessed data\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "new_ind = 0\n",
    "words = df['translated'].unique()\n",
    "for word in df['translated']:\n",
    "    matches = dict(fuzzywuzzy.process.extract(word, words, limit = 1000, scorer=fuzzywuzzy.fuzz.token_set_ratio))\n",
    "    df['w' + str(new_ind)] = 0\n",
    "    for ind in df.index:\n",
    "        df.loc[ind, 'w' + str(new_ind)] = matches[df.loc[ind, 'translated']]\n",
    "    new_ind = new_ind + 1\n",
    "\n",
    "tmp = df.loc[:,'w0':'w307'].values.astype('float')\n",
    "def symmetrize(a):\n",
    "    return np.tril(a)\n",
    "df.loc[:,'w0':'w307'] = symmetrize(tmp)\n",
    "\n",
    "\n",
    "clustered_words = {}\n",
    "cluster_number = 1\n",
    "for i in range(0,308):\n",
    "    rows_in_cluster = df.loc[df['w' + str(i)]>70,'w' + str(i)].index\n",
    "    for indx in rows_in_cluster:\n",
    "        check_list_string = ',' + ','.join([str(elem) for elem in list(clustered_words.keys())]) + ','\n",
    "        if ',' + str(indx) + ',' not in check_list_string:\n",
    "            clustered_words[indx] = ['w' + str(i), cluster_number]\n",
    "    cluster_number = cluster_number + 1\n",
    "\n",
    "for ind in df.index:\n",
    "    df.loc[ind, \"cluster\"] = clustered_words[ind][1]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-burden",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Writing results to the excel file\n",
    "wb_result = xw.books.add()\n",
    "wb_result.sheets(1).range(\"A1\").value = df.loc[:,['source', 'translated', 'cluster']]\n",
    "ws.range(\"A1\").value = \"Першоджерело\"\n",
    "ws.range(\"B1\").value = \"Виправлене першоджерело\"\n",
    "ws.range(\"C1\").value = \"Кластер\"\n",
    "wb_result.save('out.xlsx')\n",
    "wb_result.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
